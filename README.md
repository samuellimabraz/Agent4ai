# Agent4ai

Um Agente Conversacional capaz de auxiliar novos funcion√°rios na empresa Tech4Humans durante o processo de integra√ß√£o.

## Introdu√ß√£o

O agente utiliza de ferramentas de LLMs e RAG, fornecendo funcionalidades para descrever com precis√£o informa√ß√µes internas da empresa, como a divis√£o de times, produtos, valores, vis√£o e miss√£o, utilizando de uma base documental, al√©m de fornecer tutoriais e explica√ß√µes sobre ferramentas internas e gerenciamento de eventos, atrav√©s de pesquisas em tempo real e integra√ß√£o com sistema de calend√°rio.

## Solu√ß√£o

Minha solu√ß√£o utilizou como framework principal o [LangGraph](https://github.com/langchain-ai/langgraph)ü¶úüï∏, uma ferramenta construida em cima do Langchain que permite criar agentes com um alto n√≠vel de controle sobre seus estados, memoria, interrup√ß√£o, a√ß√µes e se baseia na arquitetura em grafos.

A cria√ß√£o do agente se deve pela implementa√ß√£o das ferramentas auxiliares ao LLM e a cria√ß√£o do grafo que gerencia como o agente ir√° gerar cada subresposta e resposta final.

Com essa arquitetura cada n√≥ performa uma a√ß√£o, e criamos o controle de fluxo com suas arestas de conex√£o. Podemos controlar o estado do agente em cada parte e como atuar sobre ele, com diferentes ferramentas e diluindo as tarefas em sub objetivos e planos de caminho.

Para uma melhor organiza√ß√£o, os componentes do grafo foi dividido em dois diret√≥rios principais, [chains](/agent/graph/chains/) e [nodes](/agent/graph/nodes/). Chains s√£o uma abstrta√ß√£o que o LangCahin fornece para sequencias de chamadas com um LLM, tools ou processamento de dados, assim cada chain define o prompt para o llm, a chamada de alguma ferramenta, e a estrutura de mensagem de sa√≠da do llm, padronizando a forma de opera√ß√£o. Os n√≥s utilizar√£o de seus rescpectivos chains para invokar a sequencia de chamadas, obter o resultados e tomar alguma a√ß√£o sobre eles.

![graph](/images/graph_mermaid.png)
[graph_mermaid](https://drive.google.com/file/d/1z9eoB3ERiNw3pKFK52Eh-vQQYZ20b7tc/view?usp=sharing)

### Funcionalidades
---
#### **RAG**
O conceito de Gera√ß√£o Aumentada de Recupera√ß√£o (RAG) aprimora os resultados de um LLM ao integrar informa√ß√µes espec√≠ficas e atualizadas, usando recupera√ß√£o de dados de uma determinada base de conhecimento

No contexto do desafio a t√©cninca de RAG foi necessaria para integrar ao LLM informa√ß√µes sobre a documenta√ß√£o da empresa que foi disponiblizada, pesquisa na web para obter respostas atualizadas das ferramentas externas e integra√ß√£o com o sistema de calend√°rio.

Em meu desenvolvimento criei um agente que utiliza das ideias de 
- [Adaptive-RAG](https://arxiv.org/abs/2403.14403). Um "roteador", direciona a pergunta para diferentes abordagens de recupera√ß√£o.
- [Corrective-RAG](https://arxiv.org/pdf/2401.15884.pdf). Mecanismo de fallback, plano alternativo para quando o contexto recuperado √© irrelevante para solucionar a pergunta.
- [Self-RAG](https://arxiv.org/abs/2310.11511). Um processo de avalia√ß√£o, em que se classifica a resposta do agente como alucina√ß√£o ou fora de contexto, e corrige a resposta.

#### **Roteamento**

A primeira etapa do agente com a entrada do usu√°rio, √© interpretar a quest√£o com o llm principal e direcionar o fluxo do processo para determinado n√≥. Com a ideia do Adaptive-RAG, √© possivel escolher a melhor ferramenta de recupera√ß√£o para cada tipo e tarefa especifica.
- [Router Node](/agent/graph/nodes/router_node.py), [Router Chain](/agent/graph/chains/router.py)

#### **Documenta√ß√£o**

Para o LLM conseguir utilizar as informa√ß√µes disponibilizadas sobre a empresa foi realizado as t√©cnicas de Embedding junto a busca de similaridade em banco de vetores. Onde o texto do documento √© dividido em multiplos tokens, diluindo o texto em pacotes menores, e estes recebem uma representa√ß√£o vetorial, os vetores s√£o persistidos em um banco, e posteriormente, atrav√©s de m√©tricas de similaridade √© possivel recuperar informa√ß√µes mais correlacionadas com o contexto.

- O Embedding, foi utilizado o modelo [embed-multilingual-v3.0](https://docs.cohere.com/docs/cohere-embed#multi-lingual-models), que cria embeddings de 1024 dimens√µes com um contexto com o m√°ximo de 512 tokens.

- Para o banco de vetores, foi utilizado o [MongoDB Atlas](https://www.mongodb.com/docs/atlas/), que fornece uma ferramenta de pesquisa vetorial em campos indexados. [Vector Search](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-overview/)

![doc-rag](/images/Cohere%20Multilingual%20Model.png)
[Embedding Rag](https://drive.google.com/file/d/1DsShUQCkMza8mhoc4WZTJmLWwBkT5n4c/view?usp=sharing)

Al√©m disso, na ideia do Corrective-RAG, ap√≥s o n√≥ de "retriever" extrair os melhores chunks dos documentos associados a quest√£o, estes documentos s√£o avaliados em um outro n√≥, julgando-os um a um se s√£o relevantes no contexto ou n√£o. Assim, a recupera√ß√£o n√£o se garante apenas pela busca por similaridade, mas ainda mais uma etapa de interpreta√ß√£o do LLM. 
Caso a recupera√ß√£o se deu como totalmente irrelevante, o agente √© direcionado ao web search, caso contr√°rio ele se direciona para a gera√ß√£o da resposta final. 
- [Retriever Node](/agent/graph/nodes/retrieve.py)
- [Grade Documents Node](/agent/graph/nodes/grade_document.py), [Retrievel Grade Chain](/agent/graph/chains/retrieval_grader.py)

#### **Web Search**

A integra√ß√£o com as pesquisas na web em tempo real se deu pela ferramenta [Travily](https://tavily.com/), que j√° possui [integra√ß√£o](https://python.langchain.com/v0.2/docs/integrations/retrievers/tavily/) com o framework do LangChain.

Para otimizar o processo, antes de chamar a api de busca, um n√≥ de planejamento usa do LLM para atrav√©s da quest√£o do us√°rio criar 3 melhores senten√ßas para pesquisar. Isso permite direcionar de forma precisa a pesquisa, introduzindo a interpretabilidade da quest√£o pelo LLM. Assim a api realiza 3 melhores buscas e retorna em documentos a url da fonte junto com seu conte√∫do relevante. 
- [Research Planner Node](/agent/graph/nodes/research_plan.py), [Research Planner Chain](/agent/graph/chains/planner.py)
- [Web Search Node](/agent/graph/nodes/web_search.py)

#### **Calend√°rio**

Para integra√ß√£o com sistema de calend√°rio foi utilizado a api do google clound, que permite acessar e realizar a√ß√µes com o Google Calendar. Criei uma interface que permite listar um determinado n√∫mero de eventos a partir do dia atual, criar eventos e acessar informa√ß√µes b√°sicas do usu√°rio. 
- [Calendar Tool](/agent/tools/calendar_tool.py)

O n√≥ respons√°vel pelas a√ß√µes de agenda, eventos, usa do LLM junto com uma pr√© coleta de informa√ß√£o, com os pr√≥ximos 5 eventos e informa√ß√µes do usuario, para assim decidir entre as a√ß√µes de listar, criar eventos ou somente informar algo. Com a decis√£o tomada, tamb√©m gera os par√¢metros necess√°rios para a fun√ß√£o escolhida, por exemplo, se foi decidido criar um evento ele cria todos os par√¢metros necess√°rios para usar o metodos de cria√ß√£o que a ferramenta fornece. 
- [Calendar Node](/agent/graph/nodes/calendar_node.py), [Calendar Chain](/agent/graph/chains/calendar.py)

#### **Gera√ß√£o  Final**

O n√≥ final do agente √© respons√°vel por gerar a resposta final com o LLM e as informa√ß√µes de contexto recuperadas anteriormente, junto ao hist√≥rico de conversas.

Por√©m, na ideia do Self-RAG, a resposta final passa por uma avalia√ß√£o, verificando se a resposta √© realmente √∫til para o √∫til para a entrada do usu√°rio. Caso seja, v√° para o estado final, caso contr√°rio √© retornado para o n√≥ de pesquisa.

A implementa√ß√£o est√° simplificada, para maior seguran√ßa e consist√™ncia, poderia haver um contador que inibisse do agente entrar em loop infinito, caso saia muito do contexto e n√£o alcance uma boa respsota. Al√©m disso, o escape para a pesquisa foi uma escolha r√°pida, por o n√≥ ter uma boa probabilidade de obter informa√ß√µes, que pelo menos, parecem √∫teis.

- [Generate Node](/agent/graph/nodes/generate.py), [Generate Chain](/agent/graph/chains/generation.py)
- [Answer Grader](/agent/graph/chains/answer_grader.py)

A constru√ß√£o do agente final pode ser encontrado em [agent](/agent/graph/agent.py)

## Uso

### Configura√ß√£o

1. **Instala√ß√£o**

    Primeiramente clone o repositorio:
    ```bash
    git clone https://github.com/samuellimabraz/Agent4ai.git
    ```
2. **Depend√™ncias**
 
    √â necessario um abiente com [Python 3.10+](https://www.python.org/downloads/release/python-3100/) e realizar a instala√ß√£o das dependencias que se encontra no arquivo de [requerimentos](requirements.txt):
    ```bash
    pip install -r requirements.txt
    ```
3. **Chaves de API**

    O projeto utiliza diferentes ferramentas que requerem de tokens de valida√ß√£o para acessa-l√°s.
    - **[Groq](https://groq.com/)**: Plataforma que oferece a infer√™ncia r√°pida em nuvem com LPUs do LLM principal.
    - **[Cohere](https://dashboard.cohere.com/)**: Fornece o modelo de Embedding utilizado para ferramenta de retriever.
    - **[Tavily](https://tavily.com/)**: Ferramenta de web search otimizada para RAG
    - **[MongoDB](https://www.mongodb.com/docs/manual/reference/connection-string/#find-your-mongodb-atlas-connection-string)**: Banco de dados utilizado para consulta de vetores e armazenamento do hist√≥rico de conversa.
    - **[Google Clound](https://developers.google.com/calendar/api/quickstart/python)**: Para ter acesso as funcionalidades do Google Calendar, mas tamb√©m o ID da conta √© utilizado para o gerenciamento de mem√≥ria da conversa. Para simplifica√ß√£o, esse credenciamento √© obrigatorio para inicializa√ß√£o do agente. Siga as intru√ß√µes do link para configurar a conta.

    Ao final, crie um arquivo ```.env``` com as chaves obtidas, ficar√° semelhante a isso:
    ```
    GROQ_API_KEY=...
    COHERE_API_KEY=...
    TAVILY_API_KEY=..
    MONGODB_CONNECTION_STRING=...
    ```

---
### Execu√ß√£o

- V√° para o diret√≥rio principal:
    ```
    cd Agent4ai
    ```

- O agente foi disponibilizado atrav√©s de uma API, com uso da [FastAPI](https://fastapi.tiangolo.com/) e uma interace gr√°fica com [Gradio](https://www.gradio.app/guides/quickstart).

    Para executar o projeto, utilize:

    ```bash
    uvicorn app:app 
    ```

    Assim incializar√° a API, que fornece opera√ß√µes de POST para envio da mensagem de requisi√ß√£o e opera√ß√£o para limpeza do hist√≥rico de conversa. A documenta√ß√£o √© disponibilizada com Swagger, que pode ser acessada em /docs

- Para inciar a interface gr√°fica use:

    ```bash
    python .\interface\gui.py
    ```
Demo:

[demo](https://drive.google.com/file/d/1BkTkj2FdIEG94zlQSeOCI_VniqRPHvsP/view?usp=sharing)

## Refer√™ncias 

- [DeepLearning.AI - AI Agents in LangGraph](https://learn.deeplearning.ai/accomplishments/fa462bc1-6c3c-4af0-8ba5-b5c54630fdf4?usp=sharing)
- [Advanced RAG control flow with LangGraph](https://github.com/locupleto/langgraph-course/tree/main)
- [Building a RAG Agent with LangGraph, LLaMA3‚Äì70b, and Scaling with Amazon Bedrock](https://medium.com/@philippkai/building-a-rag-agent-with-langgraph-llama3-70b-and-scaling-with-amazon-bedrock-2be03fb4088b)
- [Self-Reflective RAG with LangGraph](https://blog.langchain.dev/agentic-rag-with-langgraph/)